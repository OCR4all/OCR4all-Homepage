import{_ as e,e as n}from"./app.b397120f.js";import{_ as i,a as r,b as t}from"./Abb7.3ef42e84.js";import{_ as s}from"./Abb9.0cfba348.js";import{_ as d}from"./Abb10.50a2f03b.js";import{_ as l,a}from"./Abb12-2.79fbfcce.js";import{_ as u,a as g,b as o}from"./Abb14.b01bdd70.js";import{_ as h,a as c,b as m,c as b,d as p,e as f}from"./Abb20.8d7d0e25.js";import{_ as w,a as k,b as z,c as S,d as v,e as A,f as E,g as T}from"./Abb28.bc641f93.js";import{_ as L,a as R,b as _,c as D,d as M}from"./Abb33.cecea596.js";import{_ as x}from"./Abb34.ca206ad2.js";import{_ as y}from"./Abb35.777b9e0c.js";import{_ as B,a as W}from"./Abb37.a7c11420.js";import{_ as O}from"./Abb38.47dfc288.js";import{_ as P}from"./Abb39.fcf1d8c5.js";import{_ as F}from"./Abb40.f19d0870.js";import{_ as Z}from"./Abb41.1a4d873d.js";const C={},I=n('<div class="custom-container danger"><p class="custom-container-title">Achtung</p><p>Die Seite wird gerade noch \xFCberarbeitet. Bei auftretenden Problemen <a href="mailto:florian.langhanki@uni-wuerzburg.de">kontaktieren</a> Sie uns bitte.</p></div><h2 id="_4-workflow" tabindex="-1"><a class="header-anchor" href="#_4-workflow" aria-hidden="true">#</a> 4. Workflow</h2><p>OCR4all bietet grunds\xE4tzlich zwei unterschiedliche Varianten eines OCR-Workflows an, die sich v. a. im Hinblick auf den mit ihnen verbundenen Arbeitsaufwand, damit jedoch fast zwangsl\xE4ufig auch in \xDCberpr\xFCfbarkeit von Teilergebnissen und somit Qualit\xE4t der erstellten Daten stark voneinander unterscheiden k\xF6nnen. Beide Varianten werden im Folgenden vorgestellt und eingeordnet.</p><h3 id="_4-1process-flow" tabindex="-1"><a class="header-anchor" href="#_4-1process-flow" aria-hidden="true">#</a> 4.1 Process Flow</h3><p>Die Variante des sog. \u201E<strong>Process Flow</strong>\u201C (Hauptmen\xFC \u2630 \u2192 Process Flow) bietet die M\xF6glichkeit eines nahezu vollautomatisierten Workflows. Hier werden lediglich die zur Bearbeitung vorgesehenen Scans in der rechten Seitenleiste ausgew\xE4hlt und mittels Haken danach all jene Arbeitsschritte ausgew\xE4hlt, die am vorliegenden Datenmaterial durchgef\xFChrt werden sollen.</p><p><img src="'+i+'" alt="Abb6.png"></p><p>Abb. 5: Teilkomponenten des \u201EProcess Flow\u201C.</p><p>Lediglich f\xFCr das Teilmodul \u201ERecognition\u201C muss nun noch ein geeignetes OCR-Modell oder Modellensemble (f\xFCnf gleichzeitig und miteinander agierende Einzelmodelle, s. dazu auch Kap. 4.7) zur Erkennung ausgew\xE4hlt werden (dies geschieht unter \u201ESettings\u201C \u2192 \u201ERecognition\u201D \u2192 \u201EGeneral\u201D), wie in der folgenden Abb. dargestellt, aus der Liste aller verf\xFCgbaren OCR-Modelle (\u201ELine recognition models \u2013 Available\u201C).</p><p><img src="'+r+'" alt="Abb7-2.png"></p><p>Abb. 6: Auswahl eines geeigneten OCR-Modells.</p><p>Generell ist es dabei m\xF6glich, mehr als nur ein Modell f\xFCr die Erkennung ausw\xE4hlen. Empfohlen wird dies jedoch nur dann, wenn auch unterschiedliche Typen innerhalb des zu erkennenden Drucktextes vorkommen.</p><p>Durch \u201EEXECUTE\u201C wird der \u201EProcess Flow\u201C gestartet. \xDCber Fortschrittsbalken zu den einzelnen Teilmodulen l\xE4sst sich der aktuelle Stand der automatisierten Bearbeitung verfolgen. Nach dem vollst\xE4ndigen Durchlauf des Workflows k\xF6nnen die Ergebnisse im Men\xFCpunkt \u201EGround Truth Production\u201C (\u2630) \xFCberpr\xFCft werden.</p><p><img src="'+t+'" alt="Abb7.png"></p><p>Abb. 7: Zeilenbilder mit entsprechendem OCR-Ergebnis.</p><p>Entsprechen die erstellten OCR-Texte auf Zeilenbasis der gew\xFCnschten bzw. geforderten Erkennungsgenauigkeit, k\xF6nnen bereits jetzt finale OCR-Ergebnisse (TXT und/oder PageXML) unter dem Men\xFCpunkt \u201EResult Generation\u201C (\u2630) generiert werden. Entsprechen die Ergebnisse nicht der gew\xFCnschten Genauigkeit, k\xF6nnen sie vor der Ergebnisausgabe noch einmal korrigiert werden (s. dazu Kapitel 4.8).</p><p>Neben dem sog. \u201EProcess Flow\u201C bietet OCR4all auch die M\xF6glichkeit eines <strong>sequenziellen Workflows</strong>, bei dem der Nutzer die unterschiedlichen Teilmodule (s. dazu Abb. 1) und deren zugeh\xF6rige Arbeitsschritte eigenst\xE4ndig durchf\xFChrt, um jeweils die Korrektheit und Qualit\xE4t der produzierten Daten zu gew\xE4hrleisten. Da die separaten Teilmodule aufeinander aufbauen, erscheint diese Herangehensweise v. a. im Falle der Bearbeitung fr\xFChneuzeitlicher Drucke mit aufwendigem und komplexeren Layout besonders sinnvoll.</p><p>V. a. Erstnutzern wird an dieser Stelle ohnehin geraten, mindestens einmal den nun folgenden schrittweisen Workflow der OCR durchzuf\xFChren, um die Funktionsweise der jeweiligen Teilmodule zu verstehen.</p><h3 id="_4-2preprocessing" tabindex="-1"><a class="header-anchor" href="#_4-2preprocessing" aria-hidden="true">#</a> 4.2 Preprocessing</h3><p><strong>Input:</strong> Originalbild (farbig, in Graustufen oder bin\xE4r)<br><strong>Output:</strong> entzerrtes Bin\xE4r- (und Graustufen-)Bild</p><ul><li>Dieser Bearbeitungsschritt dient der Erstellung von Bin\xE4r- und normalisierten Graustufenbildern, welche die Grundlage f\xFCr erfolgreiche Segmentierung und OCR darstellen.</li><li>In der rechten Seitenleiste werden alle Scans ausgew\xE4hlt, die bearbeitet werden sollen; alle Einstellungen (\u201ESettings (General)\u201C und \u201ESettings (Advanced)\u201C) bleiben bestehen, d. h. der Winkel der zu bearbeitenden Bilder bleibt unver\xE4ndert, ebenso die automatisch generierte Anzahl der durch das Teilmodul verwendeten CPUs (letzteres betrifft alle folgenden Teilmodule von OCR4all!).</li></ul><p><img src="'+s+'" alt="Abb9.png"></p><p>Abb. 8: Einstellungen zum Preprocessing.</p><ul><li>Der Binarisierungsvorgang kann durch einen Klick auf \u201EEXECUTE\u201D gestartet werden. Der Verlauf des Arbeitsschritts kann in der Konsole, genauer dem \u201EConsole Output\u201C, verfolgt werden. Ggf. werden in \u201EConsole Error\u201C w\xE4hrend des Binarisierungsprozesses Warnungen ausgegeben. Diese haben jedoch keine Auswirkungen auf das Ergebnis der Binarisierung.</li><li>Ob die Binarisierung erfolgreich war, kann unter \u201EProject Overview\u201D und durch den Klick auf einen beliebigen \u201EPage Identifier\u201D sowie die Bildanzeige \u201EBinary\u201D kontrolliert werden. Au\xDFerdem sollten in der Projekt\xFCbersicht in der Spalte \u201CPreprocessing\u201D f\xFCr alle bearbeiteten Bilddateien Haken erschienen sein.</li></ul><h3 id="_4-3noise-removal" tabindex="-1"><a class="header-anchor" href="#_4-3noise-removal" aria-hidden="true">#</a> 4.3 Noise Removal</h3><p><strong>Input:</strong> verunreinigte Bin\xE4rbilder<br><strong>Output:</strong> Bin\xE4rbilder ohne oder mit nur wenigen Verunreinigungen</p><ul><li>Mit Hilfe der Option Noise Removal k\xF6nnen bspw. kleinere Verunreinigungen wie Flecken und Punkte auf den Scans getilgt werden.</li><li>Klicken Sie zur Benutzung im Hauptmen\xFC auf den Arbeitsschritt \u201ENoise Removal\u201D und w\xE4hlen Sie am rechten Bildschirmrand aus, auf welche Scans dieser Vorgang angewendet werden soll. Lassen Sie alle Defaults zun\xE4chst bestehen und betrachten Sie nach der Bet\xE4tigung von \u201EEXECUTE\u201C probeweise das Ergebnis, in dem Sie auf den Schriftzug des jeweiligen Scans in der rechten Seitenleiste klicken, den Sie betrachten wollen. Unter \u201EImage Preview\u201D wird Ihnen nun in einer Gegen\xFCberstellung das Ergebnis im Vergleich mit dem unbearbeiteten Scan angezeigt. Rot eingef\xE4rbte Bildelemente wurden durch den Arbeitsschritt entfernt.</li></ul><p><img src="'+d+'" alt="Abb10.png"></p><p>Abb. 9: Einstellungen zum Teilmodul Noise Removal.</p><ul><li>Sind noch zu viele st\xF6rende Elemente auf dem Scan zu sehen, setzen Sie den Wert der \u201EMaximal size for removing contours\u201D geringf\xFCgig nach oben, f\xFChren den Arbeitsschritt durch einen Klick auf \u201EEXECUTE\u201D erneut durch und pr\xFCfen wiederum das Ergebnis.</li><li>Wurden zu viele Bildelemente entfernt, korrigieren Sie den Wert der \u201EMaximal size for removing contours\u201D nach unten.</li><li>Verfahren Sie in dieser Weise weiter, bis Sie mit dem Ergebnis zufrieden sind.</li></ul><h3 id="_4-4segmentation-\u2013-larex" tabindex="-1"><a class="header-anchor" href="#_4-4segmentation-\u2013-larex" aria-hidden="true">#</a> 4.4 Segmentation \u2013 LAREX</h3><p><strong>Input:</strong> vorverarbeitete Bilder<br><strong>Output:</strong> strukturelle Informationen zu Layoutregionen (Typ und Position) sowie deren Reading Order</p><p>LAREX dient als Tool der Segmentierung, d. h. zur Strukturierung und Klassifizierung des Layouts von Druckseiten mit Blick auf weitere Verarbeitungsschritte. Grundlegend ist dabei die Annahme, dass sich v. a. die Seiten besonders fr\xFCher Druckerzeugnisse aus einem immer wiederkehrenden Pool unterschiedlicher Layoutelemente zusammensetzen, ihr Aufbau auch werkimmanent also ein bis zu einem bestimmten Grad einheitlicher ist. Aus diesem Grund stehen dem Benutzer verschiedene Werkzeuge und Hilfsmittel zur Verf\xFCgung, um eine Druckseite so zu strukturieren, d. h. zu segmentieren, dass alle f\xFCr die noch folgenden Bestandteile des Workflows notwendigen, das Seitenlayout betreffenden Informationen einer Seite ad\xE4quat erfasst werden. Dazu geh\xF6ren neben der grundlegenden Unterscheidung Text vs. Nicht-Text (also bspw. Text vs. Bild/Holzschnitt) sowie deren weiterer Spezifizierung (also im Falle des Textes bspw. \xDCberschrift, Haupttext, Seitenzahl etc.) auch Informationen zur Reading Order, d. h. der Lese- und Nutzungsreihenfolge der vorhandenen Layoutelemente.</p><h4 id="_4-4-1voreinstellungen" tabindex="-1"><a class="header-anchor" href="#_4-4-1voreinstellungen" aria-hidden="true">#</a> 4.4.1 Voreinstellungen</h4><ul><li>Men\xFC: \u201ESegmentation\u201C \u2192 \u201ELAREX\u201C</li><li>\u201ESegmentation image type\u201C: \u201EBinary\u201C, falls mit den binarisierten Bilddateien weitergearbeitet werden soll; \u201EDespeckled\u201C, falls zuvor der Arbeitsschritt \u201ENoise Removal\u201C vollzogen wurde</li><li>\u201EOPEN LAREX\u201C \u2192 LAREX \xF6ffnet sich in einem neuen Tab.</li></ul><p><img src="'+l+'" alt="Abb11.png"></p><p>Abb. 10: LAREX-Einstellungen.</p><p>Mittig wird nun die erste der ausgew\xE4hlten Scanseiten angezeigt. Es sind bereits erste Segmentierungsergebnisse zu sehen. Diese entstehen aufgrund einer automatischen Segmentierung einer jeden Scanseite, sobald diese das erste Mal aufgerufen wird. Gespeichert sind diese Ergebnisse nicht. Aufgabe des Users ist es im Folgenden, Einstellungen vorzunehmen, um die angezeigten automatischen Segmentierungsergebnisse an das Layout des vorliegenden Werks anzupassen bzw. h\xE4ndische Nachkorrekturen dieser Ergebnisse vorzunehmen, um ein korrektes Segmentierungsergebnis zu erhalten.</p><p><img src="'+a+'" alt="Abb12-2.png"></p><p>Abb. 11: Startanzeige und automatische Segmentierungsergebnisse.</p><h4 id="_4-4-2ubersicht-und-werkzeugleiste" tabindex="-1"><a class="header-anchor" href="#_4-4-2ubersicht-und-werkzeugleiste" aria-hidden="true">#</a> 4.4.2 \xDCbersicht und Werkzeugleiste</h4><p>In der linken Seitenleiste werden alle zu segmentierenden und zuvor ausgew\xE4hlten Scans angezeigt. Je nach aktuellem Bearbeitungsstatus erhalten sich unterschiedliche, farbige Markierungen in der rechten unteren Ecke:</p><ul><li>Ausrufezeichen, orange: \u201EThere is no segmentation for this page.\u201C \u2013 Aktuell liegen keine Segmentierungsergebnisse f\xFCr diese Scanseite vor.</li><li>Warndreieck, orange: \u201ECurrent segmentation may be unsaved.\u201C \u2013 Die aktuellen Segmentierungsergebnisse sind noch nicht gespeichert (s. u.).</li><li>Diskette, gr\xFCn: \u201ESegmentation was saved in this session.\u201C \u2013 F\xFCr die Scanseite liegen die Segmentierungsergebnisse, gespeichert als XML-Dateien, vor.</li><li>Schloss, gr\xFCn: \u201EThere is a segmentation for this page on the server.\u201C \u2013 Die einzelnen, gespeicherten Segmentierungsergebnisse wurden nach Abschluss der Segmentierung des Gesamtwerks als korrekt best\xE4tigt (s. u.).</li></ul><p><img src="'+u+'" alt="Abb12.png"></p><p>Abb. 12: Verschiedene Anzeigemodi</p><ul><li>\xDCber die Buttons &#39;0&#39; und &#39;1&#39; ist es m\xF6glich, zwischen der binarisierten (schwarz-wei\xDF) und der normalisierten (Graustufen) Bilddarstellung zu wechseln. Die entsprechende Auswahl wird f\xFCr alle restlichen Seiten des Werks gemerkt. Es ist jederzeit m\xF6glich, den Anzeigemodus wieder zu \xE4ndern.</li><li>In der Kopfleiste finden sich verschiedene Werkzeuge und Werkzeuggruppen zur Navigation und Bearbeitung:</li></ul><p><img src="'+g+'" alt="Abb13.png"></p><p>Abb. 13: Verschiedene Men\xFCpunkte der Werkzeugleiste.</p><ul><li><em>BILDCHEN</em> <strong>Open a different book</strong>: F\xFCr die in OCR4all eingebundene Version von LAREX sind hier keine Einstellungen oder Ver\xE4nderungen notwendig!</li><li><strong>Image Zoom</strong>: \xDCber die hier m\xF6glichen Einstellungen wird die allgemeine Darstellung von Scanseiten und Bilddateien in LAREX geregelt, d. h. z. B. Zoomeinstellungen. Allerdings k\xF6nnen diese Einstellungen und Darstellungsoptionen auch mithilfe der Maus und/oder des Touchpads geregelt werden (einfaches Verschieben der angezeigten Seite durch gehaltenen Linksklick auf den Scan und Bewegung der Maus; Zoom \xFCber Mausrad oder Zoomeinstellungen des Touchpads).</li><li><em>BILDCHEN</em> <strong>Undo</strong> und <em>BILDCHEN</em> <strong>Redo</strong>: Zur\xFCcknehmen oder Wiederholen der letzten Benutzeraktion. Auch \xFCbliche Tastenkombinationen sind hier m\xF6glich (z. B.: STRG + Z = letzte Aktion r\xFCckg\xE4ngig machen).</li><li><em>BILDCHEN</em> Delete selected items: Entfernt die aktuell ausgew\xE4hlten Regionen.</li><li><strong>RoI</strong>, <strong>Region</strong>, <strong>Segment</strong>, <strong>Order</strong>: Hier werden, erg\xE4nzt durch die rechte Seitenleiste, die verschiedenen M\xF6glichkeiten der Scanbearbeitung und Segmentierung aufgezeigt. W\xE4hrend die in der Werkzeugleiste aufgef\xFChrten Optionen im Allgemeinen einer spezifischen Bearbeitung der aktuell vorliegenden Scanseite dienen (s. u.), werden dagegen in der rechten Seitenleiste v. a. scan\xFCbergreifende und werkbezogene Optionen angezeigt.</li></ul><p><img src="'+o+'" alt="Abb14.png"></p><p>Abb. 14: Einstellungen der rechten Seitenleiste.</p><p>Auch sie k\xF6nnen jedoch jederzeit erg\xE4nzt, ver\xE4ndert und angepasst werden. Hilfreich und sinnvoll ist es in diesem Fall, alle vorgenommenen Einstellungen hinsichtlich der Erkennungsparameter (\u201EParameters\u201C) sowie der in einem Werk vorhandenen und vom User festgelegten Layoutelemente (\u201ERegions\u201C) jederzeit unter \u201ESettings\u201C zu speichern und bei der n\xE4chsten Verwendung des Tools wiederzuverwenden. Dies erm\xF6glicht die Arbeit mit werkspezifischen Einstellungen.</p><h4 id="_4-4-3werkbezogene-einstellungen-regions-parameters-reading-order-settings" tabindex="-1"><a class="header-anchor" href="#_4-4-3werkbezogene-einstellungen-regions-parameters-reading-order-settings" aria-hidden="true">#</a> 4.4.3 Werkbezogene Einstellungen: Regions, Parameters, Reading Order, Settings</h4><ul><li>\u201E<strong>Regions</strong>\u201C: Jede Scan- und damit Werk- und Textseite besteht entsprechend der Konzeption und Idee von LAREX aus unterschiedlichen Layoutelementen. Darunter fallen z. B. der Haupttext, \xDCberschriften, Marginalien, Seitenzahlen usw. Jedem dieser Layoutelemente muss in LAREX eine bestimmte, definierte \u201Eregion\u201C bzw. Layoutregion zugeordnet werden. Diese Zuordnung wird mit Blick auf weitere Bearbeitungsschritte und die eigentliche Erkennung des dargestellten Inhalts konsistent \xFCber das gesamte zu segmentierende Werk erfolgen! Neben einigen vordefinierten und festgelegten Layoutregionen wie \u201Eimage\u201C (z. B. graphische Darstellungen wie Holzschnitte, Zierinitialen usw.), \u201Eparagraph\u201C (Haupttext) oder \u201Epage_number\u201C (Seitenzahl) k\xF6nnen durch den User weitere, werkspezifische Layoutregionen unter \u201ECreate\u201C hinzugef\xFCgt und definiert werden, d. h. neben einer Darstellungsfarbe kann unter \u201EminSize\u201C auch die Mindestgr\xF6\xDFe einer als entsprechende Layoutregion zu erkennenden Text- oder Bildregion auf der Scanseite festgelegt werden. Mithilfe des \u201ESAVE\u201C-Buttons wird die so definierte Layoutregion der werkspezifischen Liste hinzugef\xFCgt.</li></ul><p><img src="'+h+'" alt="Abb15.png"></p><p>Abb. 15: Einstellungsoptionen unter Regions.</p><ul><li>Zus\xE4tzlich bietet \u201E<strong>Regions</strong>\u201C die M\xF6glichkeit, bestimmten Layoutregionen einen festen und vordefinierten Platz auf einer Scanseite zuzuweisen, der bei der automatischen Segmentierung der nachfolgenden Seiten (beim ersten \xD6ffnen dieser) \xFCbernommen wird, d. h.: Wiederholt sich das Layout einer Seite \xFCber ein Werk hinweg immer wieder, so kann hier eine Art der Layoutschablone erzeugt werden, mit deren Hilfe die automatische Segmentierung verbessert und damit die Anzahl der korrigierenden Eingriffe durch den User im Folgenden potentiell verringert wird. Um die Lage der Layoutregionen an das Layout der Seiten innerhalb des Werkes anzupassen, kann die aktuelle Lage der Layoutregionen angezeigt und danach durch einfaches Ausw\xE4hlen der Regionen auf der Scanseite ver\xE4ndert werden.</li></ul><p><img src="'+c+'" alt="Abb16.png"></p><p>Abb. 16: Anzeige von Layoutregionen und Layoutschablone.</p><ul><li>Wird durch den User eine neue \u201ERegion\u201C definiert, so kann die Lage dieser \xFCber die Werkzeugleiste und die nachfolgende Option \u201ERegion\u201C \u2192 \u201ECreate a region rectangle (Shortcut: 1)\u201C festgelegt und auch danach jederzeit ver\xE4ndert werden. F\xFCr \u201Eimages\u201C kann keine Layoutregion auf der Scanseite verortet werden.</li></ul><p><img src="'+m+'" alt="Abb17.png"></p><p>Abb. 17: Einrichtung neuer Layoutregionen.</p><ul><li><p>Gleichzeitig ist es dar\xFCber hinaus nicht immer sinnvoll, f\xFCr alle Layoutregionen fixe Pl\xE4tze \xFCber das gesamte Werk auf Scanseiten festzulegen. V. a. wenn die Lage bestimmter \u201Eregions\u201C wie \xDCberschriften, Motti, aber auch Seitenzahlen oder Bogensignaturen immer wieder variiert, kann es durch die Festlegung definierter Pl\xE4tze zu Fehlerkennungen kommen. Sinnvoller ist es in diesem Fall, entsprechende Layoutelemente nach der automatischen Segmentierung h\xE4ndisch zu korrigieren. Soll die Lage von Layoutregionen ganz gel\xF6scht werden, wird sie einfach mithilfe eines Klicks ausgew\xE4hlt und \xFCber \u201EEntf\u201C gel\xF6scht.</p></li><li><p>\u201E<strong>Parameters</strong>\u201C: Hier werden allgemeine Parameter der Text- und Bilderkennung festgelegt. Die Notwendigkeit der Einstellung werkspezifischer Parameter erkl\xE4rt sich aus dem sehr uneinheitlichen Layout und Druckbild v. a. fr\xFChneuzeitlicher Drucke. So k\xF6nnen hier W\xF6rter und auch ganze Zeilen in unterschiedlichen Abst\xE4nden zueinander gedruckt sein. Um bspw. zu vermeiden, dass diese als eigene Layoutregionen und nicht zugeh\xF6rig zu einem zusammenh\xE4ngenden Textabschnitt erkannt werden, kann unter \u201EText Dilation\u201C die Ausdehnung einer als Text erkannten Region in X- und Y-Richtung definiert werden. Auf diese Weise k\xF6nnen Zeilen- und Wortabst\xE4nde \xFCberwunden und weitst\xE4ndige Textabschnitte miteinander verschmolzen werden. Es empfiehlt sich hier, werkspezifisch unterschiedliche Einstellungen zu testen, um diese zu optimieren.</p></li></ul><p><img src="'+b+'" alt="Abb18.png"></p><p>Abb. 18: Einstellungen in Parameters.</p><ul><li>\u201E<strong>Settings</strong>\u201C: Unter dem Men\xFCpunkt \u201ESettings\u201C k\xF6nnen die unter \u201ERegions\u201C und \u201EParameters\u201C festgelegten Segmentierungs- und Darstellungsoptionen gespeichert und bei Bedarf, z. B. bei der Wiederaufnahme der Segmentierung eines Werks nach einer Unterbrechung, wieder geladen werden. Dazu dienen die Buttons \u201ESAVE SETTINGS\u201C und \u201ELOAD SETTINGS\u201C. Im Falle des Speicherns wird eine XML-Datei erzeugt, die beim Laden wieder ausgew\xE4hlt werden muss (auf \u201ELoad Settings\u201C klicken, in sich \xF6ffnendem Fenster entsprechende Datei ausw\xE4hlen und \xF6ffnen). Zus\xE4tzlich gibt es hier ebenfalls die M\xF6glichkeit, sich Segmentierungsergebnisse bereits gespeicherter Seiten noch einmal laden und damit anzeigen zu lassen. Dazu wird unter \u201EAdvanced Settings\u201C auf \u201ELOAD NOW\u201C geklickt. Falls f\xFCr die vorliegende Scanseite einmal eine XML-Datei mit Segmentierungsergebnissen gespeichert wurde, wird diese nun geladen. Gleichzeitig kann diese letzte Option automatisiert ab dem Start von LAREX realisiert sein, sofern bereits entsprechende Segmentierungsergebnisse vorliegen.</li></ul><p><img src="'+p+'" alt="Abb19.png"></p><p>Abb. 19: Settings.</p><ul><li>\u201E<strong>Reading Order</strong>\u201C: Soll in den sich der Segmentierung anschlie\xDFenden und im weiteren Verlauf erstellbaren Erkennungsergebnissen der Text einer Seite in der richtigen Reihenfolge wiedergegeben werden, so ist die Festlegung einer Reading Order derjenigen Layoutelemente unerl\xE4sslich, die Text enthalten. Diese Festlegung kann, bspw. bei klarem und einfachem Druckbild, automatisiert erfolgen. Bei komplexeren Layoutstrukturen empfiehlt es sich dagegen, die Reading Order manuell festzulegen, um Fehler in der Reihenfolge zu vermeiden. Dazu wird in der Werkzeugleiste in der Gruppe \u201EOrder\u201C zwischen den Werkzeugen \u201EAuto generate a reading order\u201C und \u201ESet a reading order\u201C ausgew\xE4hlt.</li></ul><p><img src="'+f+'" alt="Abb20.png"></p><p>Abb. 20: Rechts: Reading Order in der Werkzeugleiste.</p><ul><li>Erfolgt ein Klick auf die automatisierte Erstellung der Reading Order, erscheint in der rechten Seitenleiste unter \u201EReading Order\u201C eine naive Auflistung aller Text beinhaltenden Layoutelemente von oben nach unten. Wird die Reihenfolge manuell festgelegt, m\xFCssen die einzelnen Elemente auf der Scanseite in der richtigen Reihenfolge durch den User angeklickt werden, um in der erw\xE4hnten Auflistung zu erscheinen (s. u.). Die einzelnen Elemente der Reading Order k\xF6nnen mittels Drag- and-Drop in ihrer Reihenfolge ver\xE4ndert werden und einzelne Elemente \xFCber das zugeh\xF6rige M\xFClleimer-Icon entfernt werden. Auch die Reading Order kann, wie alle anderen Eingriffe in LAREX, vor dem finalen Abspeichern der Segmentierungsergebnisse immer wieder ge\xE4ndert werden.</li></ul><h4 id="_4-4-4beispielhafte-segmentierung-einer-scanseite" tabindex="-1"><a class="header-anchor" href="#_4-4-4beispielhafte-segmentierung-einer-scanseite" aria-hidden="true">#</a> 4.4.4 Beispielhafte Segmentierung einer Scanseite</h4><p>LAREX erstellt mit dem Laden einer Scanseite automatisch erste Segmentierungsergebnisse. Diese m\xFCssen im Folgenden korrigiert werden.</p><p>Der folgende Segmentierungsdurchgang bezieht sich auf die vierte Seite des Standardwerkes \u201ECirurgia\u201C, welches beim Download der OCR4all-Ordnerstruktur LINKhierLINK heruntergeladen werden kann.</p><p><strong>Fehleranalyse</strong>: Welche Layoutelemente wurden richtig erkannt, welche fehlerhaft, welche gar nicht? Befinden sich auf den Seitenr\xE4ndern Benutzerspuren, Bord\xFCren, Verschmutzungen oder Textteile, die nicht erkannt werden sollen, das Segmentierungsergebnis jedoch beeinflussen?</p><p><img src="'+w+'" alt="Abb21.png"></p><p>Abb. 21: Automatisches Segmentierungsergebnis f\xFCr die vierte Seite aus \u201ECirurgia\u201C.</p><p><strong>\u201ERegion of Interest\u201C (RoI)</strong>: Befinden sich au\xDFerhalb der Abschnitte eine Scanseite, die f\xFCr die Erkennung relevant sind, Elemente, die das Segmentierungsergebnis negativ beeinflussen (z. B. Benutzerspuren, Verunreinigungen, Bibliotheksstempel etc.), so kann eine RoI festgelegt werden, um diese Bereiche von Vornherein aus der automatischen Segmentierung auszuschlie\xDFen. Dazu wird in der Werkzeugleiste unter \u201ERoI\u201C die Option \u201ESet the Region of Interest\u201C ausgew\xE4hlt und mithilfe der linken Maustaste ein Rechteck um den zu segmentierenden Inhalt der Scanseite gelegt.</p><p><img src="'+k+'" alt="Abb22.png"></p><p>Abb. 22: Festlegungen einer Region of Interest.</p><p>Ist die RoI festgelegt, erfolgt ein Klick auf das auf der rechten Seite befindliche Feld \u201E<strong>SEGMENT</strong>\u201C \u2013 Elemente, die sich au\xDFerhalb der RoI befinden, werden nun nicht mehr ber\xFCcksichtigt. Wichtig: Wird eine RoI gesetzt, \xFCbertr\xE4gt sich diese auch auf alle Scanseiten, die im weiteren Verlauf der Arbeit an einem Werk aufgerufen werden. Da sich die segmentierungsrelevanten Abschnitte auf einer Seite aufgrund unterschiedlicher Faktoren immer wieder verschieben k\xF6nnen, ist es wahrscheinlich, auch die RoI in Abst\xE4nden immer wieder den Seitengegebenheiten anpassen zu m\xFCssen. Dazu k\xF6nnen einfach einzelne Bereiche der RoI angeklickt und mit Hilfe der Maus verschoben werden.</p><p>Unabh\xE4ngig von der RoI kann durch die Option \u201ECreate a ignore rectangle\u201C eine sog. Ignore-Region erstellt werden, mit deren Hilfe kleinr\xE4umigere Scanbestandteile ignoriert und somit von der Segmentierung ausgeschlossen werden k\xF6nnen.</p><p><strong>Korrektur fehlerhaft erkannter Layoutelemente</strong>: Falsch erkannte Layoutelemente k\xF6nnen in ihrer Typisierung ge\xE4ndert werden. Dazu klickt man mit der rechten Maustaste auf das entsprechende Element \u2013 im sich \xF6ffnenden Auswahlfenster kann die korrekte Region ausgew\xE4hlt werden.</p><p><img src="'+z+'" alt="Abb23.png"></p><p>Abb. 23: Korrektur einer fehlerhaften Typisierung.</p><p>Soll die \xDCberschrift aufgrund ihrer Verwachsung mit dem ihr folgenden Text von diesem abgetrennt werden, so kann dies auf drei Arten erfolgen:</p><p>Zum einen bietet sich die M\xF6glichkeit, um die zu klassifizierende Region ein Rechteck zu ziehen. Dazu wird in der Werkzeugleiste unter \u201ESegment\u201C die Option \u201ECreate a fixed segment rectangle\u201C (Shortcut: 3) ausgew\xE4hlt, anschlie\xDFend mithilfe der Maus ein Fenster um die entsprechende Region gezogen und im sich darauf \xF6ffnenden Auswahlmen\xFC die richtige Benennung ausgew\xE4hlt. Zum zweiten kann die Auswahl der zu klassifizierenden Region mit Hilfe eines Polygons vorgenommen werden. Dies bietet sich vor allem bei komplexen, un\xFCbersichtlichen oder verschachtelten Layouts an, in denen schr\xE4ge Kanten, Rundungen in Bildern und Holzschnitten oder im Textblock platzierte Zierinitialen o. \xC4. vorkommen. Hierzu wird in der Werkzeugleiste unter \u201ESegment\u201C diesmal die Option \u201ECreate a fixed segment polygon\u201C (Shortcut: 4) ausgew\xE4hlt und die zu klassifizierende Layoutregion in einer Punktlinie eingefasst, deren Ende mit dem Beginn verkn\xFCpft und damit zu einem Polygon zusammengefasst wird. Auch hier erscheint nach Verbindung von Anfangs- und Endpunkt ein Auswahlmen\xFC, in dem die richtige Benennung ausgew\xE4hlt werden kann.</p><p>Die dritte M\xF6glichkeit umfasst die Zerteilung des als paragraph erkannten Textblockes aus \xDCberschrift und Haupttext mithilfe einer Schnittlinie. Diese wird in der Werkzeugleiste unter \u201ESegment\u201C mit der Option \u201ECreate a cut line\u201C (Shortcut: 5) ausgew\xE4hlt.</p><p><img src="'+S+'" alt="Abb24.png"></p><p>Abb. 24: Auswahl der Schnittlinie in der Werkzeugleiste.</p><p>Mit Hilfe der linken Maustaste wird die Linie polygonartig durch mehrere Klicks quer durch das aufzuspaltende Layoutelement gezogen. Durch einen Doppelklick auf die linke Maustaste kann ein Endpunkt der Linie gesetzt wird.</p><p><img src="'+v+'" alt="Abb25.png"></p><p>Abb. 25: Festlegung der Schnittlinie zwischen zwei zu trennenden Bereichen eines Layoutelements.</p><p>Wird nun auf \u201ESEGMENT\u201C geklickt, wird der als ein Layoutelement erkannte Bereich in zwei unterschiedliche Layoutelemente aufgetrennt. Anschlie\xDFend kann der Bereich der \xDCberschrift mittels Rechtsklick und entsprechender Auswahl (s. o.) korrekt umbenannt werden.</p><p><img src="'+A+'" alt="Abb26.png"></p><p>Abb. 26: Korrekte Typisierung der getrennten Bereiche.</p><p>Sollen Layoutelemente, falsch gezogene Schnittlinien, verzogene Polygone etc. gel\xF6scht werden, k\xF6nnen diese einfach durch einen Linksklick der Maus markiert und anschlie\xDFend \xFCber \u201EEntf\u201C oder in der Werkzeugleiste mittels \u201EDelete selected items\u201C gel\xF6scht werden.</p><p><strong>Festlegung der \u201EReading Order\u201C</strong> (s. o.):</p><p><img src="'+E+'" alt="Abb27.png"></p><p>Abb. 27: Festlegung der Reading Order.</p><p><strong>Speichern des Segmentierungsergebnisses des aktuellen Scans</strong>: Das Speichern der Ergebnisse erfolgt durch einen Klick auf den \u201ESAVE RESULT\u201C-Button oder durch Strg + S. In diesem Moment wird in der OCR4all-Ordnerstruktur eine XML-Datei mit den Segmentierungsergebnissen abgelegt.</p><p><img src="'+T+'" alt="Abb28.png"></p><p>Abb. 28: Speichern von Segmentierungsergebnissen.</p><p><strong>Anschlie\xDFend kann in der linken Seitenleiste der n\xE4chste Scan ausgew\xE4hlt werden.</strong> Soll die Segmentierung eines Scans nachtr\xE4glich noch einmal ge\xE4ndert werden, so muss danach einfach die neue Segmentierung einmal abgespeichert werden \u2013 auf diese Weise wird die dann veraltete XML-Datei durch die aktuelle und neue \xFCberschrieben.</p><h4 id="_4-4-5weitere-bearbeitungsoptionen" tabindex="-1"><a class="header-anchor" href="#_4-4-5weitere-bearbeitungsoptionen" aria-hidden="true">#</a> 4.4.5 Weitere Bearbeitungsoptionen</h4><p>Dar\xFCber hinaus bestehen generell <strong>weitere Bearbeitungsm\xF6glichkeiten</strong> von Scans, die im Folgenden angezeigt werden sollen:</p><ul><li>F\xFCr L\xF6schungen oder die Zusammenf\xFChrung mehrere Layoutelemente zu einer zusammenh\xE4ngenden Region ist es praktisch, diese <strong>gleichzeitig ausw\xE4hlen</strong> zu k\xF6nnen. Dazu halten Sie die Umschalttaste gedr\xFCckt und ziehen mit Hilfe der Maus ein Rechteck um die entsprechenden Layoutregionen. Die Regionen m\xFCssen sich dazu vollst\xE4ndig innerhalb des Rechtecks befinden. Alle auf diese Weise ausgew\xE4hlten Layoutregionen erscheinen nun blau umrandet.</li><li><strong>\u201ESelect contours to combine (with \u201EC\u201C) to segments (see function combine)\u201C</strong> (Shortcut: 6): Dieses Werkzeug kann verwendet werden, um auch auf sehr eng und detailreich bedruckten Seiten zu einem optimalen Segmentierungsergebnis zu gelangen. Grundlegende Idee ist, dass Layoutelemente durch die Konturen der einzelnen Typen des Textes, den sie beinhalten, oder exakt durch die R\xE4nder von Bildern und Zierinitialen begrenzt werden \u2013 ohne \xFCbersch\xFCssigen, durch h\xE4ndisches Segmentieren entstehenden Rand, der immer wieder zur Element\xFCberschneidungen und damit zu Ungenauigkeiten mit Folgen f\xFCr die OCR f\xFChren kann. <ul><li>Um die Funktion auszuf\xFChren, erfolgt zuerst ein Klick auf den entsprechenden Button in der Werkzeugleiste oder der Shortcut 6. Daraufhin werden alle als Layoutelemente der Seite erkannten Bestandteile blau eingef\xE4rbt.</li></ul></li></ul><p><img src="'+L+'" alt="Abb29.png"></p><p>Abb. 29: Konturenanzeige.</p><ul><li>Klickt man nun auf nur einzelne Typen oder sogar Typenbestandteile, verf\xE4rben sie sich violett \u2013 sie sind nun ausgew\xE4hlt.</li></ul><p><img src="'+R+'" alt="Abb30.png"></p><p>Abb. 30: Konturenauswahl.</p><ul><li>Es k\xF6nnen auch mehrere Typen, ganze W\xF6rter und Zeilen oder Teile ganzer Layoutelemente ausgew\xE4hlt werden (s. o.: Umschalt + Auswahl \xFCber Aufziehen eines Rechtecks). Erfolgt nach der Auswahl bestimmter Typen, W\xF6rter, Zeilen etc. der Shortcut C, so werden alle ausgew\xE4hlten Elemente der Scanseite zu einem eigenen Layoutelement zusammengefasst, unabh\xE4ngig von ihrer vorherigen Elementzugeh\xF6rigkeit. Die Eingrenzung des so entstehenden neuen Layoutelements ist dabei im Vergleich zu den automatisch erkannten Elementen sehr viel feiner, weil sie sich wie besprochen direkt an den R\xE4ndern einzelner Typen oder Bilder orientiert. Auf diese Weise ist eine sehr viel detailliertere Segmentierung als \xFCber die standardisierten Tools m\xF6glich.</li></ul><p><img src="'+_+'" alt="Abb31.png"></p><p>Abb. 31: Zusammenfassung ausgew\xE4hlter Konturen zu einem neuen Layoutelement.</p><ul><li>Der anschlie\xDFende Klick auf \u201ESEGMENT\u201C fixiert den Eingriff. Abschlie\xDFend kann das entstandene, eigenst\xE4ndige Layoutelement entsprechend obigen Vorgehens nach Belieben umbenannt werden.</li></ul><p><img src="'+D+'" alt="Abb32.png"></p><p>Abb. 32: Typisierung des segmentierten Layoutelements.</p><ul><li><strong>\u201ECombine selected segments or contours\u201C</strong> (Shortcut: C): Um mehrere, einzeln erkannte Layoutelemente zu einer einzigen zusammenzufassen, w\xE4hlen sie die gew\xFCnschten Regionen vollst\xE4ndig aus (s. o.) und klicken \u201EC\u201C bzw. auf den entsprechenden Button in der Werkzeugleiste.</li><li><strong>\u201EFix/unfix segments, for it to persist a new auto segmentation\u201C</strong> (Shortcut: F): Mit Hilfe dieser Funktion k\xF6nnen Layoutelemente \xFCber einen weiteren Segmentierungsvorgang einer Seite hinaus fixiert werden. Dazu wird das entsprechende Layoutelement durch Anklicken markiert, danach folgt ein Klick auf \u201EF\u201C oder den entsprechenden Button. Fixierte Elemente erscheinend mit einer gestrichelten Umrandung. Um die Fixierung zu verwerfen, wird der Vorgang einfach wiederholt.</li><li><strong>Zoomen</strong>: Mithilfe des Mausrads kann bei sehr klein gedrucktem Text oder kompliziertem Layout an den Scan herangezoomt werden. Mithilfe der Leertaste wird die Anzeige in ihrem urspr\xFCnglichen Zustand zur\xFCckgesetzt.</li><li>Bei besonders kleinteiligem und damit aufwendigem Layout k\xF6nnen Segmentierungsergebnisse durch spezielle <strong>Detaileingriffe</strong> weiter optimiert werden. Die Umrisse der als Layoutelemente erkannten Bereiche einer Scanseite werden bei genauerem Hinsehen als Punktlinie dargestellt.</li></ul><p><img src="'+M+'" alt="Abb33.png"></p><p>Abb. 33: Punktlinie als Umriss von Layoutelementen.</p><ul><li>Diese Punkte k\xF6nnen einzeln oder auch zu mehreren verschoben werden, um bspw. bei sehr engem Druckbild \xDCberschneidungen mit anderen, angrenzenden Layoutelemente zu vermeiden. Einzelne Punkte k\xF6nnen durch einen gehaltenen Linksklick mit der Maus verschoben werden. Durch einen Klick auf die Linie k\xF6nnen dar\xFCber hinaus bei Bedarf neue Punkte geschaffen werden. Auch das L\xF6schen von Punkten ist mithilfe von \u201EEntf\u201C m\xF6glich.</li><li><strong>\u201ELOAD RESULTS\u201C</strong>: Mit Hilfe dieser Funktion k\xF6nnen bereits bestehende Segmentierungsergebnisse f\xFCr eine bestimmte Scanseite direkt aus der Ordnerstruktur von OCR4all in LAREX geladen werden.</li></ul><h4 id="_4-4-6abschluss-der-segmentierung-mit-larex" tabindex="-1"><a class="header-anchor" href="#_4-4-6abschluss-der-segmentierung-mit-larex" aria-hidden="true">#</a> 4.4.6 Abschluss der Segmentierung mit LAREX</h4><ul><li>Sind alle Segmentierungsarbeiten f\xFCr ein Werk in LAREX abgeschlossen, d. h. wurden f\xFCr jede Seite eines Werks Ergebnisse abgespeichert, so liegen diese nun in der bekannten Ordnerstruktur von OCR4all vor.</li><li>Ob die Segmentierung und Speicherung der Ergebnisse erfolgreich war, kann danach abschlie\xDFend im Men\xFCpunkt \u201EPost Correction\u201C in der Spalte \u201ESEGMENTS\u201C kontrolliert werden (s. u.).</li></ul><h3 id="_4-5line-segmentation" tabindex="-1"><a class="header-anchor" href="#_4-5line-segmentation" aria-hidden="true">#</a> 4.5 Line Segmentation</h3><p><strong>Input</strong>: vorverarbeitete Bilder und Segmentierungsinformationen in Form von PageXML- Dateien<br><strong>Output</strong>: extrahierte Textzeilen in den PageXML-Dateien</p><ul><li>In direkter Vorbereitung auf die folgende OCR werden in diesem Arbeitsschritt alle mittels LAREX festgelegten und klassifizierten Layoutelemente in denen Text enthalten ist, in Zeilen zerschnitten (die OCR funktioniert zeilenbasiert) und im zugeh\xF6rigen PageXML abgelegt.</li></ul><p><img src="'+x+'" alt="Abb34.png"></p><p>Abb. 34: Einstellungen zur Line Segmentation.</p><ul><li>Generell k\xF6nnen auch hier die vorhandenen Einstellungen beibehalten werden. <strong>Wichtige Einschr\xE4nkung mit Blick auf das vorhandene Seitenlayout</strong>: Liegt ein zwei- oder mehrspaltiges Seitenlayout vor und wurden die entsprechenden Textspalten in LAREX jeweils als eigenst\xE4ndige Haupttexte segmentiert, muss bei \u201EMaximum # of whitespace column separators\u201D der voreingestellte Wert von -1 (Best\xE4tigung, dass kein mehrspaltiges Layout vorhanden und eine Spaltentrennung deshalb nicht erw\xFCnscht ist) wie folgt ge\xE4ndert werden: <ul><li>Zur Erkl\xE4rung: \u201E<strong>Whitespace column separators</strong>\u201D sind spaltenweise gesehen die wei\xDFen Randbereiche um Textbl\xF6cke.</li><li>Bei einem <strong>zweispaltigen Layout</strong>, dessen Text inhaltlich fortlaufend ist, d. h. die jeweils ersten Zeilen der beiden Textbl\xF6cke keine inhaltliche Einheit bilden, muss der Wert bei \u201EMaximum # of whitespace column separators\u201D auf 3 gesetzt werden: Diese Angabe ergibt sich aus dem linken whitespace der linken Textspalte, dem rechten whitespace der rechten Textspalte sowie dem gemeinsamen whitespace zwischen beiden Textspalten.</li><li>Bei einem <strong>dreispaltigen Layout</strong> m\xFCsste der Wert entsprechend auf 4 ver\xE4ndert werden usw.</li></ul></li><li>Sobald alle Einstellungen wie gew\xFCnscht getroffen sind, klicken Sie auf \u201EEXECUTE\u201D und \xFCberpr\xFCfen die Ergebnisse abermals unter \u201EProject Overview\u201D. Hier erhalten die einzelnen Zeilen als Unterpunkte der einzelnen Layoutelemente (s. o.).</li><li>Vor allem bei der Line Segmentation ist immer wieder die Anwendung der erweiterten Einstellungen (\u201ESettings (Advanced)\u201D) hilfreich \u2013 v. a. dann, wenn in der Konsole Fehlermeldungen angezeigt werden und die Zeilensegmentierung entsprechend nicht fehlerfrei durchgef\xFChrt werden konnte. Beispielsweise wird bei zu kleinen Buchstaben h\xE4ufig die in den Defaults festgehaltene Minimalbreite von ganzen Zeilen unterschritten. Diese Minimalbreite kann jedoch bspw. durch die Herabsetzung des Wertes \u201EMinimum scale permitted\u201D unter dem Men\xFCpunkt \u201ELimits\u201D ge\xE4ndert werden. Die wiederholte Durchf\xFChrung der Line Segmentation f\xFCr die ausgew\xE4hlten Scanseiten wird dann ohne Fehlermeldung korrekt vollzogen.</li><li>\xDCberpr\xFCfbar ist die korrekte Zeilensegmentierung auch unter dem Men\xFCpunkt \u201EPost Correction\u201D im Reiter \u201ELines\u201C (s. u.).</li></ul><h3 id="_4-6recognition" tabindex="-1"><a class="header-anchor" href="#_4-6recognition" aria-hidden="true">#</a> 4.6 Recognition</h3><p><strong>Input</strong>: Textzeilen und ein oder mehrere OCR-Modelle<br><strong>Output</strong>: OCR-Output in Textform f\xFCr jede in den PageXML-Dateien vorliegenden Zeile</p><ul><li>Der Arbeitsschritt der Recognition stellt die Erkennung von Text auf Grundlage der w\xE4hrend der Line Segmentation (s. o.) erstellten Zeilenbilder aller Layoutelemente mit Text dar.</li><li>W\xE4hlen Sie dazu den Men\xFCpunkt \u201ERecognition\u201D. In der rechten Seitenleiste finden Sie nun nur Scans bzw. Druckseiten des bearbeiteten Werkes aufgelistet, f\xFCr die bereits alle Vorbedingungen der OCR erf\xFCllt, d. h. alle bisher beschriebenen Arbeitsschritte (mit Ausnahme der \u201ENoise Removal\u201C) durchgef\xFChrt wurden. W\xE4hlen Sie jene aus, f\xFCr die Sie Text produzieren lassen wollen.</li><li>W\xE4hlen Sie nun unter \u201ELine recognition models\u201D in der Spalte \u201EAvailable\u201D all jene Modelle oder Modellensembles aus, die zur Erkennung ihres Textes entsprechend der vorhandenen Schriftarten und Typen (z. B. fr\xFChneuzeitliche bzw. historische Fraktur, Kursive, historische Antiqua etc.) geeignet sind. Die Verwendung von Modellensembles (f\xFCnf gleichzeitig und gemeinsam agierende Einzelmodelle) statt einfacher Einzelmodelle wird dringend empfohlen! Durch einfaches Anklicken werden sie in die Spalte \u201ESelected\u201D verschoben. \xDCber die \u201ESearch\u201C-Funktion ist eine Filterung nach Namen m\xF6glich, wenn besonders viele Modelle zur Auswahl stehen.</li></ul><p><img src="'+y+'" alt="Abb35.png"></p><p>Abb. 35: Auswahl eines gemischten Modellensembles f\xFCr die Texterkennung.</p><ul><li>Eine Anpassung der erweiterten Einstellung ist in aller Regel nicht notwendig.</li><li>Klicken Sie nun auf \u201EEXECUTE\u201D und warten Sie die Texterkennung \xFCber die Fortschrittsanzeige und die Konsole ab.</li><li>Ist die Erkennung abgeschlossen, k\xF6nnen Sie die Ergebnisse f\xFCr jedes Zeilenbild unter dem Men\xFCpunkt \u201EGround Truth Production\u201D einsehen.</li></ul><h3 id="_4-7ground-truth-production" tabindex="-1"><a class="header-anchor" href="#_4-7ground-truth-production" aria-hidden="true">#</a> 4.7 Ground Truth Production</h3><p><strong>Input</strong>: Zeilenbild und entsprechender OCR-Output, wenn verf\xFCgbar<br><strong>Output</strong>: zeilenbasierte Ground Truth</p><ul><li>Unter dem Men\xFCpunkt \u201EGround Truth Production\u201D k\xF6nnen die im Teilmodul Recognition erzeugten Texte eingesehen, korrigiert und als Trainingsgrundlage in Form von sog. Ground Truth abgespeichert werden.</li><li>Das zugrundeliegende Korrekturtool ist dreispaltig aufgebaut: Auf der linken Seite finden sich, jeweils untereinander, die ausw\xE4hlbaren Seiten. Mittig werden die durch den Workflow erzeugten Zeilenbilder aus den Textseiten (s. o.) sowie die aus ihnen generierten Zeilen OCR-Text angezeigt. Diese standardm\xE4\xDFig dargestellte Anzeige wird als \u201EText View\u201C bezeichnet.</li></ul><p><img src="'+B+'" alt="Abb36.png"></p><p>Abb. 36: Ground Truth Production mit \u201EText View\u201D.</p><ul><li>\xDCber die Option \u201ESwitch to Page View\u201D in der Werkzeugleiste besteht die M\xF6glichkeit, von der \u201EText View\u201C auf die \u201EPage View\u201C zu wechseln. In dieser Ansicht k\xF6nnen die einzelnen Textzeilen im visuellen Gesamtkontext des Seitenlayouts bearbeitet werden. Nutzen Sie die Option \u201ESwitch to Text View\u201C, um wieder auf die \u201EText View\u201C umzuschalten.</li></ul><p><img src="'+W+'" alt="Abb37.png"></p><p>Abb. 37: Ground Truth Production mit \u201EPage View\u201D.</p><ul><li>Auf der rechten Seite der Anzeige befindet sich das sog. Virtual Keyboard, in welchem Sonderzeichen (Ligaturen, Abk\xFCrzungen, Diakritika etc.) aufgef\xFChrt werden. Diese k\xF6nnen durch einfaches Anklicken entsprechend der Position des Cursors in die Textzeilen auf der linken Seite eingef\xFCgt werden. Um Zeichen zum Keyboard hinzuzuf\xFCgen, wird einfach das Plus-Icon bet\xE4tigt und das entsprechende Zeichen mittels Copy und Paste in das sich \xF6ffnende Formular eingegeben und durch Bet\xE4tigung der \u201ESave\u201C-Schaltfl\xE4che best\xE4tigt. Sollen Zeichen aus dem Keyboard gel\xF6scht werden, zieht man diese lediglich mit der Maus auf das M\xFClleimer-Icon der Delete-Option. Sind alle gew\xFCnschten Ver\xE4nderungen vorgenommen, wird das Keyboard durch einen Klick auf \u201ESave\u201D gespeichert und danach mittels \u201ELock\u201D gesperrt. Mithilfe der Optionen \u201ELoad\u201D und \u201ESave\u201D k\xF6nnen werkspezifische Keyboards im System abgespeichert und jederzeit neu geladen werden \u2013 bspw., wenn man seine Textkorrekturen unterbricht oder sich das Keyboard auch f\xFCr die Arbeit mit einem anderen Werk eignet.</li><li>\xDCber die Schaltfl\xE4che &#39;Preset&#39; k\xF6nnen vorgefertigte Virtual-Keyboards ausgew\xE4hlt werden.</li><li>Um einzelne Zeilen bei fehlerhafter Erkennung innerhalb der \u201EText View\u201C zu korrigieren, klicken Sie in die entsprechende Zeile hinein. Die daraufhin vertikal zentrierte Zeile kann nun bearbeitet werden. Befinden Sie sich innerhalb der \u201EPage View\u201C, so kann der zugeh\xF6rige Zeilentext per Linksklick auf die entsprechende Zeile angezeigt werden. Im nun ge\xF6ffneten Textfeld k\xF6nnen ebenfalls \xC4nderungen am Zeilentext vorgenommen werden. Um die jeweils n\xE4chste Zeile anzuw\xE4hlen, bet\xE4tigen Sie die \u201ETabulator\u201C-Taste. Die weiteren Arbeitsschritte sind innerhalb beider Anzeigen \xE4quivalent. Haben sie alle Eingriffe vorgenommen und liegt damit eine entsprechend fehlerfreie Zeile vor, bet\xE4tigen Sie die \u201EEnter\u201C-Taste. Die soeben bearbeitete Zeile f\xE4rbt sich gr\xFCn, d. h.: Diese Zeile wird nach dem Speichern der bearbeiteten Seite \xFCber die Schaltfl\xE4che \u201ESAVE RESULT\u201C (Shortcut: Strg + S) innerhalb von OCR4all nun automatisch als Ground Truth abgespeichert. Sie kann nun mit allen weiteren korrigierten Zeilen als Trainingsgrundlage werkspezifischer Modelle sowie zur Evaluation der genutzten OCR-Modelle dienen oder wird Ihnen bei der Generierung Ihrer Endergebnisse (s. u.) automatisch mit ausgegeben.</li><li>Sto\xDFen Sie w\xE4hrend Ihrer Korrekturarbeiten auf fehlerhafte Zeilenbilder (bspw. halbierte, an falscher Stelle getrennte Zeilen oder sogar Doppelzeilenbilder), so lassen Sie die entsprechende Textzeile leer und speichern darin keine Ground Truth, da diese Textinformationen in Kombination mit fehlerhaften Zeilenbildern zu Problemen w\xE4hrend des Trainings f\xFChren k\xF6nnten.</li><li>Wird w\xE4hrend der Korrektur eines Werks mittels der Ground Truth Production durch den Benutzer festgestellt, dass der Grad der Erkennung durch gemischte Modelle aufgrund unterschiedlicher Faktoren noch nicht ausreicht, um eine manuelle, abschlie\xDFende Textkorrektur ohne zu gro\xDFen zeitlichen Aufwand durchzuf\xFChren, so bietet OCR4all die Option des Trainings werkspezifischer Modelle. Diese haben werkspezifisch im Allgemeinen h\xF6here Erkennungsraten als gemischte Modelle.</li></ul><h3 id="_4-8evaluation" tabindex="-1"><a class="header-anchor" href="#_4-8evaluation" aria-hidden="true">#</a> 4.8 Evaluation</h3><p><strong>Input</strong>: zeilenbasierte OCR-Texte und entsprechende Ground Truth<br><strong>Output</strong>: Fehlerstatistiken</p><ul><li>Der Men\xFCpunkt Evaluation dient der Ermittlung der Erkennungsrate eines aktuell verwendeten Modells (gemischt oder werkspezifisch).</li><li>Um diese zu generieren, werden all jene Scans in der rechten Seitenleiste ausgew\xE4hlt, die mittels dieses aktuellen Modells erkannt und danach in der \u201EGround Truth Production\u201D korrigiert wurden. Klickt der Nutzer auf \u201EEXECUTE\u201D und l\xE4sst s\xE4mtliche Einstellungen unver\xE4ndert, so wird ihm in der Konsole eine Tabelle ausgegeben: Ganz oben in der Ausgabe finden sich als Prozentsatz die Fehlerrate sowie die Gesamtanzahl der Fehler (\u201Eerrs\u201D). Darunter werden \u2013 tabellarisch gelistet durch den Vergleich von Ausgabetext der Recognition und w\xE4hrend der Korrektur erstellter Ground Truth \u2013 die gefundenen Fehler angezeigt. In der ersten Spalte ist dabei der korrigierte Text zu erkennen (\u201EGT\u201D), in der zweiten Spalte der urspr\xFCnglich durch das Modell erkannte (\u201EPRED\u201D), dahinter die H\xE4ufigkeit des Auftretens genau jenes Fehlers sowie der Prozentsatz eben dieses Fehlers an der Gesamtfehlermenge.</li></ul><p><img src="'+O+'" alt="Abb38.png"></p><p>Abb. 38: Evaluationsergebnis mit Gesamtfehlerrate und den zehn h\xE4ufigsten Fehler sowie deren Prozentsatz an der Gesamtfehlermenge.</p><ul><li>Mittels dieser tabellarischen Listung sowie der Erkennungsrate (100% - Fehlerrate) kann nun durch den Nutzer die Absch\xE4tzung \xFCber die Sinnhaftigkeit eines (neuerlichen) Trainings von werkspezifischen Modellen erfolgen.</li></ul><h3 id="_4-9training" tabindex="-1"><a class="header-anchor" href="#_4-9training" aria-hidden="true">#</a> 4.9 Training</h3><p><strong>Input</strong>: Zeilenbilder mit entsprechender Ground Truth sowie optional bereits bestehende OCR-Modelle, die als sog. Pretraining und Datengrundlage des Modelltrainings genutzt werden<br><strong>Output</strong>: ein oder mehrere OCR-Modelle</p><p>Generell muss es das Ziel sein, einen insgesamt m\xF6glichst fehlerfreien Text zu erhalten!<br> Warum dann aber die Erstellung werkspezifischer Modelle mittels des Trainings-Moduls statt einfacher, abschlie\xDFender Textkorrektur?</p><p>\u2192 Je besser das Modell, welches zur Texterkennung genutzt wird, desto k\xFCrzere f\xE4llt die Korrekturzeit aus. Idee und Sinn eines kontinuierlichen Modelltrainings sind es also, mit fortlaufendem Korrekturfortschritt auch immer bessere Modelle zu trainieren und somit den Korrekturaufwand f\xFCr die danach noch zu korrigierenden Seiten des Werkes auf ein Minimum zu reduzieren.</p><ul><li>Innerhalb des Trainingstools k\xF6nnen auf Grundlage aller zu einem Werk vorliegenden Zeilen Ground Truth werkspezifische Modelle bzw. -ensembles trainiert werden. Dazu werden in den allgemeinen Einstellungen folgende Werte eingetragen: <ul><li>\u201E<strong>The number of folds</strong> (= the number of models) <strong>to train</strong>\u201C: <strong>5</strong> \u2192 Es wird im Folgenden ein Modellensemble, bestehend aus f\xFCnf Einzelmodellen, trainiert.</li><li>\u201E<strong>Only train a single fold</strong> (= a single model)\u201C: <em>Nichts eintragen!</em> \u2192 Es werden alle f\xFCnf Einzelmodelle statt nur eines einzelnen trainiert.</li><li>\u201E<strong>Number of models to train in parallel</strong>\u201C: <strong>-1</strong> \u2192 Alle Modelle des Ensembles werden gleichzeitig trainiert.</li><li>\u201E<strong>Keep all characters loaded from the last model</strong>\u201D: Ausw\xE4hlen, wenn alle in den \u201EPretraining\u201D-Modellen enthaltenen Zeichen im zu trainierenden Modell beibehalten werden sollen, also zu dessen Whitelist hinzugef\xFCgt werden.</li><li>\u201E<strong>Whitelist characters to keep in the model</strong>\u201D: Liste von Zeichen, die beim Training und im daraus entstehenden Modell ber\xFCcksichtigt werden. Alle Zeichen au\xDFerhalb dieser \u201EWhitelist\u201C werden nicht ber\xFCcksichtigt.</li><li>\u201EPretraining\u201C:<br> \u201E<strong>Train each model based on different existing models</strong>\u201C (Im Folgenden \xF6ffnen sich f\xFCnf Dropdown-Listen; in jede wird eines der gemischten Modelle des Modellensembles eingetragen, das wie empfohlen zur ersten Erkennung von Text im vorliegenden Werk genutzt wurde; egal bei welcher Trainingsiteration der Nutzer steht: Auch wenn bspw. bereits das dritte werkspezifische Modell trainiert wird \u2013 es werden trotzdem immer die f\xFCnf zu Beginn verwendeten grundlegenden gemischten Modelle eingetragen)<br><strong>ODER</strong><br> \u201E<strong>Train all models based on one existing model</strong>\u201C (Wurde die erste Texterkennung auf Grundlage eines einzelnen gemischten Modells durchgef\xFChrt, so wird nur ein Modell eingetragen; jedoch gilt auch hier, dass bei jeder Iteration eben dieses gemischte Modell erneut angegeben werden muss).</li><li>\u201E<strong>Data augmentation</strong>\u201C: <em>Nichts eintragen.</em> \u2192 Aber: beschreibt die Anzahl der Datenerweiterungen pro Zeile. Es kann hier ein Wert, bspw. 5, angegeben werden, um damit die Menge des Trainingsmaterials zu erh\xF6hen, auf der trainiert wird. Dies kann zur Erstellung besserer Modelle f\xFChren, ben\xF6tigt aber deutlich mehr Trainingszeit.</li><li>\u201E<strong>Skip retraining on real data only</strong>\u201C: <em>Nicht ausw\xE4hlen!</em></li></ul></li><li>Die erweiterten Einstellungen bleiben unver\xE4ndert.</li></ul><p><img src="'+P+'" alt="Abb39.png"></p><p>Abb. 39: Einstellungen f\xFCr das Training von werkspezifischen Modellensembles.</p><ul><li>Mittels \u201EEXECUTE\u201C wird das Training gestartet. Im Folgenden kann das Training der Konsole nachvollzogen werden. Je nach Gesamtmenge der vorhandenen Zeilen Ground Truth variieren die Trainingszeiten.</li><li>Entsprechend obiger Einstellungen wird durch das Training ein werkspezifisches Modellensemble, bestehend aus f\xFCnf Einzelmodellen, erstellt, welches in ocr4all/models/Werktitel/0 gespeichert wird. Das Modellensemble tr\xE4gt folglich den Namen \u201E0\u201C. Es kann nun, zur weiteren Arbeit am vorliegenden Werk und Verbesserung der Erkennung innerhalb des Men\xFCpunkts \u201ERecognition\u201C und der Spalte der ausw\xE4hlbaren Modelle, zur Erkennung neuer Textseiten verwendet werden. Soll ein zweites werkspezifisches Modellensemble erstellt werden, mit Hilfe dessen bspw. m\xF6gliche Schw\xE4chen des ersten behoben werden k\xF6nnen, wird erneut vorgegangen wie hier beschrieben. Dem neuen werkspezifischen Modell wird dann automatisch die Bezeichnung \u201E1\u201C zugewiesen. Die Bezeichnungen weiterer Modellensembles setzt sich nach diesem Schema fort.</li></ul><h3 id="_4-10post-correction" tabindex="-1"><a class="header-anchor" href="#_4-10post-correction" aria-hidden="true">#</a> 4.10 Post Correction</h3><p><strong>Input</strong>: Segmentierungsinformationen f\xFCr vorverarbeitete Bilder und zugeh\xF6riger Text<br><strong>Output</strong>: Korrigierte Segmentierungsinformationen und Text</p><p>Unter dem Men\xFCpunkt \u201EPost Correction\u201C k\xF6nnen die in den vorherigen Teilmodulen erstellten Segmentierungsinformationen und Texte manuell angepasst und korrigiert werden. Das Teilmodul ist hierbei in drei Ebenen untergliedert:</p><ul><li>Unter dem Reiter \u201ESEGMENTS\u201C k\xF6nnen die in der Segmentierung erstellten Regionen und deren Reading Order seitenweise angepasst werden. Hierf\xFCr stehen einige der aus LAREX bekannten Werkzeuge (s. o.) zur Verf\xFCgung. Beachten Sie, dass Ver\xE4nderungen auf dieser Ebene ebenfalls Auswirkung auf die folgenden Ebenen haben. So f\xFChrt beispielsweise das Entfernen einer Region und das Speichern dieser \xC4nderung zum Verlust der zugeh\xF6rigen Zeilen und Texte.</li><li>Der Reiter \u201ELINES\u201C erm\xF6glicht die manuelle Anpassung der automatischen Zeilenerkennung. So k\xF6nnen analog zur vorhergehenden Auszeichnung der Regionen, einzelne Zeilen hinzugef\xFCgt, deren Form und Position ver\xE4ndert oder diese entfernt werden. Auch die Reading Order kann auf Zeilenebene manuell angepasst werden. Diese Aktionen werden wie bei LAREX unter Verwendung verschiedener Werkzeuge aus der Werkzeugleiste und der Seitenleiste durchgef\xFChrt.</li></ul><p><img src="'+F+'" alt="Abb40.png"></p><p>Abb. 40: Anpassung der zeilenbasierten Reading Order in der \u201EPost Correction\u201C.</p><ul><li>Unter \u201ETEXT\u201C ist das schon zuvor behandelte \u201EGround Truth Production\u201C-Teilmodul (s. o.) zu finden, mittels dessen die zu den Zeilen zugeordneten Texte korrigiert werden k\xF6nnen.</li></ul><h3 id="_4-11result-generation" tabindex="-1"><a class="header-anchor" href="#_4-11result-generation" aria-hidden="true">#</a> 4.11 Result Generation</h3><p><strong>Input</strong>: OCR-Ergebnisse auf Zeilenbasis, optional Ground Truth (wenn vorhanden) und zus\xE4tzliche Daten aus der Segmentierung (LAREX) und Zeilensegmentierung<br><strong>Output</strong>: endg\xFCltiger Output als Text (einzelne Textzeilen zusammengefasst zu Seiten und Volltext) und PageXML auf Seitenbasis</p><p><img src="'+Z+'" alt="Abb41.png"></p><p>Abb. 41: Result Generation.</p><ul><li>Sind die Erkennungs- und/oder Korrekturarbeiten an einem Werk aus Sicht des Nutzers abgeschlossen, so k\xF6nnen Ergebnisse in Form von TXT- sowie XML-Dateien generiert werden. Sie werden unter ocr4all/data/results gespeichert.</li><li>Unter \u201ESettings\u201D kann ausgew\xE4hlt werden, ob Text- oder PageXML-Dateien erstellt werden sollen. Im Falle der Text-Dateien wird sowohl f\xFCr jede Scanseite eine einzelne TXT erstellt, als auch eine zusammenh\xE4ngende, die den Gesamttext des bearbeiteten Werks beinhaltende ausgegeben.</li><li>Die PageXML-Dateien werden auf Scanseitenbasis ausgegeben und enthalten Angaben zum Erstellungsdatum, zu letzten Datei\xE4nderungen, zu Metadaten der sich auf sie beziehenden Scanseite, zur Seitengr\xF6\xDFe, zu auf der Seite enthaltenen Layoutelementen inklusive deren genaue Koordinaten, zur Reading Order der vorhandenen Layoutelemente, zu den einzelnen Textzeilen sowie den Text der Zeilen selbst.</li></ul>',171);function G(V,K){return I}var de=e(C,[["render",G],["__file","Summary.html.vue"]]);export{de as default};
