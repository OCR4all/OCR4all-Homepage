{"version":3,"file":"99.app.js","mappings":";;;;;;;;;;;;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ECtDA;EAAA,uEAAmD,EAAE,EAAC,WAAW;IAAjE,mCAAuC,CAAgD;UAAvF;QAAA;;;UAAA,kCAAkE,UAAQ;;;;IAA1E;;EAAA;EAAA,uEAA4G,EAAE,EAAC,wBAAwB;IAAvI,mCAAgG,CAA0E;UAA1K;QAAA;;;UAAA,kCAAwI,uBAAqB;;;;IAA7J;;EAAA;EAAA,uEAA+L,EAAE,EAAC,4BAA4B;IAA9N,mCAAmL,CAAoF;UAAvQ;QAAA;;;UAAA,kCAA+N,6BAA2B;;;;IAA1P;;EAAA;EAAA,uEAA4R,EAAE,EAAC,WAAW;IAA1S,mCAAgR,CAAgD;UAAhU;QAAA;;;UAAA,kCAA2S,UAAQ;;;;IAAnT;;EAAA;EAAA,uEAAqV,EAAE,EAAC,UAAU;IAAlW,mCAAyU,CAA8C;UAAvX;QAAA;;;UAAA,kCAAmW,SAAO;;;;IAA1W;;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;;;;;AEA0E;AAC1E;AACA,CAAmC;AACnC;AACA,iDAAiD,2BAAa;AAC9D;AACA,SAAS,SAAS;AAClB;;;AAGA,iDAAe","sources":["webpack://OCR4all.github.io/./docs/.vuepress/.temp/pages/about.html.js","webpack://OCR4all.github.io/./docs/.vuepress/.temp/pages/about.html.vue","webpack://OCR4all.github.io/./docs/.vuepress/.temp/pages/about.html.vue?5cf9","webpack://OCR4all.github.io/./docs/.vuepress/.temp/pages/about.html.vue?88ae"],"sourcesContent":["export const data = {\n  \"key\": \"v-22a39d25\",\n  \"path\": \"/about.html\",\n  \"title\": \"Über OCR4all\",\n  \"lang\": \"de-GER\",\n  \"frontmatter\": {\n    \"lang\": \"de-GER\",\n    \"title\": \"Über OCR4all\",\n    \"description\": \"Erfahren Sie mehr über das OCR4all-Projekt\"\n  },\n  \"excerpt\": \"\",\n  \"headers\": [\n    {\n      \"level\": 3,\n      \"title\": \"Workflow\",\n      \"slug\": \"workflow\",\n      \"children\": []\n    },\n    {\n      \"level\": 3,\n      \"title\": \"Kooperation mit OCR-D\",\n      \"slug\": \"kooperation-mit-ocr-d\",\n      \"children\": []\n    },\n    {\n      \"level\": 3,\n      \"title\": \"Berichterstattung (Auswahl)\",\n      \"slug\": \"berichterstattung-auswahl\",\n      \"children\": []\n    },\n    {\n      \"level\": 3,\n      \"title\": \"Zitation\",\n      \"slug\": \"zitation\",\n      \"children\": []\n    },\n    {\n      \"level\": 3,\n      \"title\": \"Funding\",\n      \"slug\": \"funding\",\n      \"children\": []\n    }\n  ],\n  \"filePathRelative\": \"about.md\",\n  \"git\": {\n    \"updatedTime\": 1631100062000,\n    \"contributors\": [\n      {\n        \"name\": \"Isabel\",\n        \"email\": \"isabel.mueller1@stud-mail.uni-wuerzburg.de\",\n        \"commits\": 6\n      }\n    ]\n  }\n}\n","<nav class=\"table-of-contents\"><ul><li><RouterLink to=\"#workflow\">Workflow</RouterLink></li><li><RouterLink to=\"#kooperation-mit-ocr-d\">Kooperation mit OCR-D</RouterLink></li><li><RouterLink to=\"#berichterstattung-auswahl\">Berichterstattung (Auswahl)</RouterLink></li><li><RouterLink to=\"#zitation\">Zitation</RouterLink></li><li><RouterLink to=\"#funding\">Funding</RouterLink></li></ul></nav>\n<p>OCR4all ist eine Software, die zur digitalen Texterschließung vornehmlich sehr früh gedruckter Werke entwickelt wurde.\nDa deren Drucktypen und oft komplex gestalteten Layoutkonzeptionen die Erkennungsmöglichkeiten vieler anderer\nTexterkennungsprogramme übersteigen, bedarf es hier der Möglichkeit, den Digitalisierungsvorgang variabel, korpus- und\nwerkspezifisch zu gestalten. Verständlich und selbstständig anwendbar spricht der in OCR4all vorgeschlagene\nsemi-automatische OCR-Workflow dabei auch einen dezidiert nicht-informatischen Nutzerkreis an und kombiniert\nunterschiedliche Arbeitswerkzeuge und Tools innerhalb einer einheitlichen Benutzeroberfläche.\nDer ständige Wechsel zwischen unterschiedlichen Programmen ist deshalb nicht mehr notwendig.\nMit dem <a href=\"http://kallimachos.de/kallimachos/index.php/Kallimachos_II_(Eingehende_Darstellung)#AP1:_OCR-Optimierung\" target=\"_blank\" rel=\"noopener noreferrer\">Abschluss<OutboundLink/></a>\nder zweiten Projektphase des BMBF-geförderten Verbundprojekts <a href=\"http://kallimachos.de\" target=\"_blank\" rel=\"noopener noreferrer\">Kallimachos<OutboundLink/></a> wird die Software nun\nam <a href=\"https://www.uni-wuerzburg.de/zpd\" target=\"_blank\" rel=\"noopener noreferrer\">Zentrum für Philologie und Digitalität<OutboundLink/></a> der Universität etabliert, um sie einer\nmöglichst breiten Nutzergruppe dauerhaft frei verfügbar zu machen.</p>\n<h3 id=\"workflow\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#workflow\" aria-hidden=\"true\">#</a> Workflow</h3>\n<p>Von der Vorverarbeitung der zur bearbeitenden Bilddateien (sog. Preprocessing) über die Layoutsegmentierung (sog.\nRegion Segmentation mit <a href=\"https://github.com/OCR4all/LAREX\" target=\"_blank\" rel=\"noopener noreferrer\">https://github.com/OCR4all/LAREX<OutboundLink/></a>), die Zeilensegmentierung\n(Line Segmentation) und Texterkennung (Recognition mit <a href=\"https://github.com/Calamari-OCR\" target=\"_blank\" rel=\"noopener noreferrer\">https://github.com/Calamari-OCR<OutboundLink/></a>\n) bis hin zur Korrektur der erkannten Texte (Ground Truth Production) und der Erstellung werkspezifischer OCR-Modelle in\neinem Trainingsmodul beschreibt OCR4all einen vollwertigen OCR-Workflow.</p>\n<p>Vor allem durch die Möglichkeit der Herstellung und des Trainings\nwerkspezifischer Texterkennungsmodelle können mit OCR4all bei so gut\nwie allen gedruckten Texten sehr gute Ergebnisse in der digitalen\nTexterschließung erzielt werden.</p>\n<h3 id=\"kooperation-mit-ocr-d\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#kooperation-mit-ocr-d\" aria-hidden=\"true\">#</a> Kooperation mit OCR-D</h3>\n<p>Im Sommer 2020 wurde eine Kooperation zwischen OCR4all und der\nkoordinierten Förderinitiative zur Weiterentwicklung von Verfahren der\nOptical Character Recognition – <a href=\"https://ocr-d.de\" target=\"_blank\" rel=\"noopener noreferrer\">https://ocr-d.de<OutboundLink/></a> vereinbart.\nDas Hauptziel des DFG-geförderten OCR-D Projekts ist die\nkonzeptionelle und technische Vorbereitung der Volltexttransformation\nder im deutschen Sprachraum erschienenen Drucke des 16.-18.\nJahrhunderts (VD16, VD17, VD18). Dazu wird die automatischen\nVolltexterkennung, analog zum OCR4all Ansatz, in einzelne\nProzessschritte zerlegt, die in der Open Source OCR-D-Software\nnachvollzogen werden können, mit dem Ziel, optimale Workflows für die\nzu prozessierenden alten Drucke zu erstellen und damit wissenschaftlich\nverwertbare Volltexte zu generieren.</p>\n<p>Gegenstand der Kooperation ist, neben dem fortlaufenden Austausch vor\nallem über Schnittstellen, skalierbare Softwareimplementierungen,\nErstellung und Bereitstellung von GT sowie kommende Entwicklungen im\nOCR-Bereich, eine technische Annäherung der beiden Projekte. OCR4all\nwird dazu in seiner OCR-Lösung die OCR-D Spezifikationen umsetzen und\nSchnittstellen zu OCR-D Werkzeugen realisieren. Setzt OCR4all intern\nauf OCR-D Lösungen, profitieren OCR4all Anwender:innen von der\nerweiterten Auswahl an Werkzeugen und den damit einhergehenden\nMöglichkeiten, wohingegen OCR-D eine größere Reichweite erhält und\ndurch den vereinfachten Zugang auch neue Anwendergruppen in- und\naußerhalb der VD-Massendigitalisierung erreicht.</p>\n<h3 id=\"berichterstattung-auswahl\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#berichterstattung-auswahl\" aria-hidden=\"true\">#</a> Berichterstattung (Auswahl)</h3>\n<ul>\n<li>Radiointerview SWR2 Impuls: Mittelalterliche Handschriften werden\nTextdokumente</li>\n<li><a href=\"https://fortext.net/tools/tools/ocr4all\" target=\"_blank\" rel=\"noopener noreferrer\">Toolvorstellung<OutboundLink/></a>\nim Rahmen des DFG-geförderten Projekts <a href=\"https://fortext.net\" target=\"_blank\" rel=\"noopener noreferrer\">forText<OutboundLink/></a></li>\n<li>Dr. Johann Ramminger: <a href=\"https://jramminger.github.io/ocr4all\" target=\"_blank\" rel=\"noopener noreferrer\">ocr4all - OCR for Incunables<OutboundLink/></a></li>\n<li>Der Tagesspiegel: Computertool für alte Texte</li>\n<li>Der Standard: <a href=\"https://www.derstandard.de/story/2000101916347/zuverlaessige-texterkennungs-tool-fuer-historische-druckschriften\" target=\"_blank\" rel=\"noopener noreferrer\">Zuverlässiges\nTexterkennungs-Tool für historische Druckschriften<OutboundLink/></a>\n-Augsburger Allgemeine: <a href=\"https://www.augsburger-allgemeine.de/bayern/Computer-liest-alte-Texte-id54130851.html\" target=\"_blank\" rel=\"noopener noreferrer\">Computer liest alte Texte<OutboundLink/></a></li>\n<li>einBlick: <a href=\"https://www.uni-wuerzburg.de/aktuelles/einblick/single/news/modernes-tool-fuer-alte-texte\" target=\"_blank\" rel=\"noopener noreferrer\">Modernes Tool für alte Texte<OutboundLink/></a></li>\n</ul>\n<h3 id=\"zitation\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#zitation\" aria-hidden=\"true\">#</a> Zitation</h3>\n<p>Falls Sie OCR4all verwenden, zitieren Sie bitte das zugehörige <a href=\"https://www.mdpi.com/2076-3417/9/22/4853%22\" target=\"_blank\" rel=\"noopener noreferrer\">Paper<OutboundLink/></a>:\nReul, C., Christ, D., Hartelt, A., Balbach, N., Wehner, M., Springmann, U., Wick, C., Grundig, Büttner, A., C.,\nPuppe, F.: OCR4all — An open-source tool providing a (semi-) automatic OCR workflow for historical printings,\nApplied Sciences 9(22) (2019)</p>\n<h3 id=\"funding\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#funding\" aria-hidden=\"true\">#</a> Funding</h3>\n<ul>\n<li><a href=\"https://ocr-d.de/de/\" target=\"_blank\" rel=\"noopener noreferrer\">DFG-Förderinitiative &quot;OCR-D&quot;<OutboundLink/></a>, (Phase 2 und 3)</li>\n<li><a href=\"https://www.uni-wuerzburg.de/zpd\" target=\"_blank\" rel=\"noopener noreferrer\">Zentrum für Philologie\nund Digitalität (ZPD)<OutboundLink/></a>, Universität Würzburg</li>\n<li>BMBF gefördertes Projekt <a href=\"http://kallimachos.de\" target=\"_blank\" rel=\"noopener noreferrer\">Kallimachos<OutboundLink/></a></li>\n<li><a href=\"https://www.informatik.uni-wuerzburg.de/is\" target=\"_blank\" rel=\"noopener noreferrer\">Lehrstuhl für\nKünstliche Intelligenz und Wissenssysteme<OutboundLink/></a>, Universität Würzburg</li>\n</ul>\n","export * from \"-!../../../../node_modules/vue-loader/dist/templateLoader.js??ruleSet[1].rules[1]!../../../../node_modules/@vuepress/bundler-webpack/lib/build/ssr/vuepressLoader.js!../../../../node_modules/vue-loader/dist/index.js??ruleSet[0].use[1]!./about.html.vue?vue&type=template&id=bc2c50ac\"","import { ssrRender } from \"./about.html.vue?vue&type=template&id=bc2c50ac\"\nconst script = {}\nimport { ssrContextKey } from 'vue'\nscript.ssrRender = (...args) => {\n  const ssrContext = args[2].appContext.provides[ssrContextKey]\n  ssrContext._registeredComponents.add(\"C:\\\\Users\\\\Isabel\\\\PycharmProjects\\\\OCR4all.github.io\\\\node_modules\\\\@vuepress\\\\bundler-webpack\\\\lib\\\\build\\\\ssr\\\\vuepressLoader.js!C:\\\\Users\\\\Isabel\\\\PycharmProjects\\\\OCR4all.github.io\\\\node_modules\\\\vue-loader\\\\dist\\\\index.js??ruleSet[0].use[1]!C:\\\\Users\\\\Isabel\\\\PycharmProjects\\\\OCR4all.github.io\\\\docs\\\\.vuepress\\\\.temp\\\\pages\\\\about.html.vue\")\n  return ssrRender(...args)\n}\n\n\nexport default script"],"names":[],"sourceRoot":""}