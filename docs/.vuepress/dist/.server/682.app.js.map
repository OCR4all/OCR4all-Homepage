{"version":3,"file":"682.app.js","mappings":";;;;;;;;;;;;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ECtDA;EAAA,uEAAmD,EAAE,EAAC,WAAW;IAAjE,mCAAuC,CAAgD;UAAvF;QAAA;;;UAAA,kCAAkE,UAAQ;;;;IAA1E;;EAAA;EAAA,uEAA4G,EAAE,EAAC,yBAAyB;IAAxI,mCAAgG,CAA4E;UAA5K;QAAA;;;UAAA,kCAAyI,wBAAsB;;;;IAA/J;;EAAA;EAAA,uEAAiM,EAAE,EAAC,uBAAuB;IAA3N,mCAAqL,CAA0E;UAA/P;QAAA;;;UAAA,kCAA4N,wBAAsB;;;;IAAlP;;EAAA;EAAA,uEAAoR,EAAE,EAAC,WAAW;IAAlS,mCAAwQ,CAAgD;UAAxT;QAAA;;;UAAA,kCAAmS,UAAQ;;;;IAA3S;;EAAA;EAAA,uEAA6U,EAAE,EAAC,UAAU;IAA1V,mCAAiU,CAA8C;UAA/W;QAAA;;;UAAA,kCAA2V,SAAO;;;;IAAlW;;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;EAAA;;;;;AEA0E;AAC1E;AACA,CAAmC;AACnC;AACA,iDAAiD,2BAAa;AAC9D;AACA,SAAS,SAAS;AAClB;;;AAGA,iDAAe","sources":["webpack://OCR4all.github.io/./docs/.vuepress/.temp/pages/en/about.html.js","webpack://OCR4all.github.io/./docs/.vuepress/.temp/pages/en/about.html.vue","webpack://OCR4all.github.io/./docs/.vuepress/.temp/pages/en/about.html.vue?f272","webpack://OCR4all.github.io/./docs/.vuepress/.temp/pages/en/about.html.vue?eb7a"],"sourcesContent":["export const data = {\n  \"key\": \"v-64f82839\",\n  \"path\": \"/en/about.html\",\n  \"title\": \"About\",\n  \"lang\": \"en-US\",\n  \"frontmatter\": {\n    \"lang\": \"en-US\",\n    \"title\": \"About\",\n    \"description\": \"Learn more about the OCR4all project\"\n  },\n  \"excerpt\": \"\",\n  \"headers\": [\n    {\n      \"level\": 3,\n      \"title\": \"Workflow\",\n      \"slug\": \"workflow\",\n      \"children\": []\n    },\n    {\n      \"level\": 3,\n      \"title\": \"Cooperation with OCR-D\",\n      \"slug\": \"cooperation-with-ocr-d\",\n      \"children\": []\n    },\n    {\n      \"level\": 3,\n      \"title\": \"Reporting (assortment)\",\n      \"slug\": \"reporting-assortment\",\n      \"children\": []\n    },\n    {\n      \"level\": 3,\n      \"title\": \"Zitation\",\n      \"slug\": \"zitation\",\n      \"children\": []\n    },\n    {\n      \"level\": 3,\n      \"title\": \"Funding\",\n      \"slug\": \"funding\",\n      \"children\": []\n    }\n  ],\n  \"filePathRelative\": \"en/about.md\",\n  \"git\": {\n    \"updatedTime\": 1631100062000,\n    \"contributors\": [\n      {\n        \"name\": \"Isabel\",\n        \"email\": \"isabel.mueller1@stud-mail.uni-wuerzburg.de\",\n        \"commits\": 4\n      }\n    ]\n  }\n}\n","<nav class=\"table-of-contents\"><ul><li><RouterLink to=\"#workflow\">Workflow</RouterLink></li><li><RouterLink to=\"#cooperation-with-ocr-d\">Cooperation with OCR-D</RouterLink></li><li><RouterLink to=\"#reporting-assortment\">Reporting (assortment)</RouterLink></li><li><RouterLink to=\"#zitation\">Zitation</RouterLink></li><li><RouterLink to=\"#funding\">Funding</RouterLink></li></ul></nav>\n<p>The OCR4all software was developed for the digitization of primarily\nvery early printed documents. As many text recognition programs are\noften not able to handle the high complexity of the types and layout\nconceptions these texts hold, an option to organize the process of\ndigitization in a variable way, orienting on the peculiarities of the\nspecific corpus or document is urgently needed.</p>\n<p>By combining different tools within a uniform user interface, the\nconstant need to switch between different programs is eliminated. The\ncomprehensible and intuitive handling combined with the semi-automatic\nworkflow of OCR4all explicitly addresses non-computer-scientists as\nwell.</p>\n<p>With the <a href=\"http://kallimachos.de/kallimachos/index.php/Kallimachos_II_(Eingehende_Darstellung)#AP1:_OCR-Optimierung\" target=\"_blank\" rel=\"noopener noreferrer\">closure<OutboundLink/></a>\nof the second project stage of the BMBF-funded joint project <a href=\"http://kallimachos.de\" target=\"_blank\" rel=\"noopener noreferrer\">Kallimachos<OutboundLink/></a>\nthe software is now being established at the <a href=\"https://www.uni-wuerzburg.de/zpd\" target=\"_blank\" rel=\"noopener noreferrer\">center for philology and digitally<OutboundLink/></a>\nof the University of Würzburg, which\nopens the program up for the widest possible user group.</p>\n<h3 id=\"workflow\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#workflow\" aria-hidden=\"true\">#</a> Workflow</h3>\n<p>The workflow starts with the Preprocessing of the relevant image files.\nLayout segmentation (so-called Region Segmentation carried out with\n<a href=\"https://github.com/OCR4all/LAREX\" target=\"_blank\" rel=\"noopener noreferrer\">LAREX<OutboundLink/></a> and Line Segmentation\nfollow. Next is the Text Recognition which is carried out with\n<a href=\"https://github.com/Calamari-OCR\" target=\"_blank\" rel=\"noopener noreferrer\">Calamari<OutboundLink/></a>. The final stage is\nthe correction of the recognized texts the so-called Ground Truth\nProduction. This Ground Truth is then the foundation for creating\nwork-specific OCR models in a training module. Therefore OCR4all\nentails a full-featured OCR workflow.</p>\n<p>Particularly due to the capacity to create and train work-specific\ntext recognition models, OCR4all makes achieving high-quality results\nin the digitization of texts in nearly all printed documents possible.</p>\n<h3 id=\"cooperation-with-ocr-d\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#cooperation-with-ocr-d\" aria-hidden=\"true\">#</a> Cooperation with OCR-D</h3>\n<p>In the summer of 2020, a co-operation between OCR4all and the\ncoordinated funding initiative for further development of processes\ninvolving Optical Character Recognition (<a href=\"https://ocr-d.de\" target=\"_blank\" rel=\"noopener noreferrer\">OCR-D<OutboundLink/></a>) was arranged.</p>\n<p>The main goal of the DFG-funded OCR-D project was the conceptual as\nwell as technical preparation of the mass digitization of printed texts\npublished in german-speaking areas from the 16th to the 18th century\n(VD16, VD17, VD18).</p>\n<p>For this purpose, the automatic full-text recognition, analogous to\nthe OCR4all approach, is divided into individual process steps that can\nbe reproduced in the Open Source OCR-D software. This aims to create\noptimized workflows for the old prints to be processed and thus\ngenerating scientifically applicable full texts.</p>\n<p>The aim of the co-operation is not only the continuous exchange of\ninformation mainly about interfaces, scalable software implementations,\ncreation and provision of GT but the upcoming developments in the OCR\nfield as well. Furthermore, it strives to achieve a technical\nconvergence of the two projects. For this purpose, OCR4all will\nimplement the OCR-D specifications in its OCR solution and realize its\ninterfaces for OCR-D tools. With OCR4all's internal use of OCR-D\nsolutions, OCR4all users will benefit from the extended selection of\ntools and the associated possibilities, whereas OCR-D will have a\nbroader scope and, through simplified access, will also reach new user\ngroups inside and outside VD mass digitization.</p>\n<h3 id=\"reporting-assortment\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#reporting-assortment\" aria-hidden=\"true\">#</a> Reporting (assortment)</h3>\n<ul>\n<li>Radiointerview SWR2 Impuls: Mittelalterliche Handschriften werden\nTextdokumente</li>\n<li><a href=\"https://fortext.net/tools/tools/ocr4all\" target=\"_blank\" rel=\"noopener noreferrer\">Toolvorstellung<OutboundLink/></a>\nim Rahmen des DFG-geförderten Projekts <a href=\"https://fortext.net\" target=\"_blank\" rel=\"noopener noreferrer\">forText<OutboundLink/></a></li>\n<li>Dr. Johann Ramminger: <a href=\"https://jramminger.github.io/ocr4all\" target=\"_blank\" rel=\"noopener noreferrer\">ocr4all - OCR for Incunables<OutboundLink/></a></li>\n<li>Der Tagesspiegel: Computertool für alte Texte</li>\n<li>Der Standard: <a href=\"https://www.derstandard.de/story/2000101916347/zuverlaessige-texterkennungs-tool-fuer-historische-druckschriften\" target=\"_blank\" rel=\"noopener noreferrer\">Zuverlässiges\nTexterkennungs-Tool für historische Druckschriften<OutboundLink/></a>\n-Augsburger Allgemeine: <a href=\"https://www.augsburger-allgemeine.de/bayern/Computer-liest-alte-Texte-id54130851.html\" target=\"_blank\" rel=\"noopener noreferrer\">Computer liest alte Texte<OutboundLink/></a></li>\n<li>einBlick: <a href=\"https://www.uni-wuerzburg.de/aktuelles/einblick/single/news/modernes-tool-fuer-alte-texte\" target=\"_blank\" rel=\"noopener noreferrer\">Modernes Tool für alte Texte<OutboundLink/></a></li>\n</ul>\n<h3 id=\"zitation\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#zitation\" aria-hidden=\"true\">#</a> Zitation</h3>\n<p>If you are using OCR4all please cite the corresponding <a href=\"https://www.mdpi.com/2076-3417/9/22/4853%22\" target=\"_blank\" rel=\"noopener noreferrer\">paper<OutboundLink/></a>:\nReul, C., Christ, D., Hartelt, A., Balbach, N., Wehner, M., Springmann, U., Wick, C., Grundig, Büttner, A., C.,\nPuppe, F.: OCR4all — An open-source tool providing a (semi-) automatic OCR workflow for historical printings,\nApplied Sciences 9(22) (2019)</p>\n<h3 id=\"funding\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#funding\" aria-hidden=\"true\">#</a> Funding</h3>\n<ul>\n<li><a href=\"https://ocr-d.de/en/\" target=\"_blank\" rel=\"noopener noreferrer\">DFG-funded Initiative &quot;OCR-D&quot;<OutboundLink/></a>, (phase 2 and 3)</li>\n<li><a href=\"https://www.uni-wuerzburg.de/zpd\" target=\"_blank\" rel=\"noopener noreferrer\">Zentrum für Philologie\nund Digitalität (ZPD)<OutboundLink/></a>, Universität Würzburg</li>\n<li>BMBF gefördertes Projekt <a href=\"http://kallimachos.de\" target=\"_blank\" rel=\"noopener noreferrer\">Kallimachos<OutboundLink/></a></li>\n<li><a href=\"https://www.informatik.uni-wuerzburg.de/is\" target=\"_blank\" rel=\"noopener noreferrer\">Lehrstuhl für\nKünstliche Intelligenz und Wissenssysteme<OutboundLink/></a>, Universität Würzburg</li>\n</ul>\n","export * from \"-!../../../../../node_modules/vue-loader/dist/templateLoader.js??ruleSet[1].rules[1]!../../../../../node_modules/@vuepress/bundler-webpack/lib/build/ssr/vuepressLoader.js!../../../../../node_modules/vue-loader/dist/index.js??ruleSet[0].use[1]!./about.html.vue?vue&type=template&id=1a2a2d5c\"","import { ssrRender } from \"./about.html.vue?vue&type=template&id=1a2a2d5c\"\nconst script = {}\nimport { ssrContextKey } from 'vue'\nscript.ssrRender = (...args) => {\n  const ssrContext = args[2].appContext.provides[ssrContextKey]\n  ssrContext._registeredComponents.add(\"C:\\\\Users\\\\Isabel\\\\PycharmProjects\\\\OCR4all.github.io\\\\node_modules\\\\@vuepress\\\\bundler-webpack\\\\lib\\\\build\\\\ssr\\\\vuepressLoader.js!C:\\\\Users\\\\Isabel\\\\PycharmProjects\\\\OCR4all.github.io\\\\node_modules\\\\vue-loader\\\\dist\\\\index.js??ruleSet[0].use[1]!C:\\\\Users\\\\Isabel\\\\PycharmProjects\\\\OCR4all.github.io\\\\docs\\\\.vuepress\\\\.temp\\\\pages\\\\en\\\\about.html.vue\")\n  return ssrRender(...args)\n}\n\n\nexport default script"],"names":[],"sourceRoot":""}